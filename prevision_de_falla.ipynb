{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing & Cleaning the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124494, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>device</th>\n",
       "      <th>failure</th>\n",
       "      <th>attribute1</th>\n",
       "      <th>attribute2</th>\n",
       "      <th>attribute3</th>\n",
       "      <th>attribute4</th>\n",
       "      <th>attribute5</th>\n",
       "      <th>attribute6</th>\n",
       "      <th>attribute7</th>\n",
       "      <th>attribute8</th>\n",
       "      <th>attribute9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F01085</td>\n",
       "      <td>0</td>\n",
       "      <td>215630672</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>407438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F0166B</td>\n",
       "      <td>0</td>\n",
       "      <td>61370680</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>403174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F01E6Y</td>\n",
       "      <td>0</td>\n",
       "      <td>173295968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>237394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F01JE0</td>\n",
       "      <td>0</td>\n",
       "      <td>79694024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>410186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F01R2B</td>\n",
       "      <td>0</td>\n",
       "      <td>135970480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>313173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    device  failure  attribute1  attribute2  attribute3  \\\n",
       "0  2015-01-01  S1F01085        0   215630672          56           0   \n",
       "1  2015-01-01  S1F0166B        0    61370680           0           3   \n",
       "2  2015-01-01  S1F01E6Y        0   173295968           0           0   \n",
       "3  2015-01-01  S1F01JE0        0    79694024           0           0   \n",
       "4  2015-01-01  S1F01R2B        0   135970480           0           0   \n",
       "\n",
       "   attribute4  attribute5  attribute6  attribute7  attribute8  attribute9  \n",
       "0          52           6      407438           0           0           7  \n",
       "1           0           6      403174           0           0           0  \n",
       "2           0          12      237394           0           0           0  \n",
       "3           0           6      410186           0           0           0  \n",
       "4           0          15      313173           0           0           3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig = pd.read_csv('full_devices.csv', encoding_errors='ignore')\n",
    "\n",
    "# We will keep an original copy of the\n",
    "df = df_orig.copy()\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop Duplicates (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df) before drop_duplicates:\t 124,494\n",
      "len(df) after drop_duplicates:\t 124,493\n",
      "diff:\t\t\t\t 1\n"
     ]
    }
   ],
   "source": [
    "print(f'len(df) before drop_duplicates:\\t {len(df):,}')\n",
    "print(f'len(df) after drop_duplicates:\\t {len(df.drop_duplicates()):,}')\n",
    "print(f'diff:\\t\\t\\t\\t {len(df)-len(df.drop_duplicates()):,}')\n",
    "\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Null Values (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date          0\n",
       "device        0\n",
       "failure       0\n",
       "attribute1    0\n",
       "attribute2    0\n",
       "attribute3    0\n",
       "attribute4    0\n",
       "attribute5    0\n",
       "attribute6    0\n",
       "attribute7    0\n",
       "attribute8    0\n",
       "attribute9    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No null values were found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Redundancy\n",
    "\n",
    "Observing the data, I noticed that two specific columns might be identical:\n",
    "- `attribute7` and `attribute8`\n",
    "\n",
    "Let's validate and remove one of them if that is the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7_8_identical\n",
       "True    124493\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_redundant = df.copy()\n",
    "df_redundant['7_8_identical'] = df_redundant['attribute7'] == df_redundant['attribute8']\n",
    "df_redundant['7_8_identical'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, both columns are identical, so let's remove one of them (`attribute8`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>device</th>\n",
       "      <th>failure</th>\n",
       "      <th>attribute1</th>\n",
       "      <th>attribute2</th>\n",
       "      <th>attribute3</th>\n",
       "      <th>attribute4</th>\n",
       "      <th>attribute5</th>\n",
       "      <th>attribute6</th>\n",
       "      <th>attribute7</th>\n",
       "      <th>attribute9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F01085</td>\n",
       "      <td>0</td>\n",
       "      <td>215630672</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>407438</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F0166B</td>\n",
       "      <td>0</td>\n",
       "      <td>61370680</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>403174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F01E6Y</td>\n",
       "      <td>0</td>\n",
       "      <td>173295968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>237394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F01JE0</td>\n",
       "      <td>0</td>\n",
       "      <td>79694024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>410186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F01R2B</td>\n",
       "      <td>0</td>\n",
       "      <td>135970480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>313173</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    device  failure  attribute1  attribute2  attribute3  \\\n",
       "0  2015-01-01  S1F01085        0   215630672          56           0   \n",
       "1  2015-01-01  S1F0166B        0    61370680           0           3   \n",
       "2  2015-01-01  S1F01E6Y        0   173295968           0           0   \n",
       "3  2015-01-01  S1F01JE0        0    79694024           0           0   \n",
       "4  2015-01-01  S1F01R2B        0   135970480           0           0   \n",
       "\n",
       "   attribute4  attribute5  attribute6  attribute7  attribute9  \n",
       "0          52           6      407438           0           7  \n",
       "1           0           6      403174           0           0  \n",
       "2           0          12      237394           0           0  \n",
       "3           0           6      410186           0           0  \n",
       "4           0          15      313173           0           3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns='attribute8', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date          object\n",
       "device        object\n",
       "failure        int64\n",
       "attribute1     int64\n",
       "attribute2     int64\n",
       "attribute3     int64\n",
       "attribute4     int64\n",
       "attribute5     int64\n",
       "attribute6     int64\n",
       "attribute7     int64\n",
       "attribute9     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need to convert 'date' column to datetime format\n",
    "df['date_dt'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date               object\n",
      "date_dt    datetime64[ns]\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    date_dt\n",
       "0  2015-01-01 2015-01-01\n",
       "1  2015-01-01 2015-01-01\n",
       "2  2015-01-01 2015-01-01"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df[['date','date_dt']].dtypes)\n",
    "df[['date','date_dt']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Describe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>failure</th>\n",
       "      <th>attribute1</th>\n",
       "      <th>attribute2</th>\n",
       "      <th>attribute3</th>\n",
       "      <th>attribute4</th>\n",
       "      <th>attribute5</th>\n",
       "      <th>attribute6</th>\n",
       "      <th>attribute7</th>\n",
       "      <th>attribute9</th>\n",
       "      <th>date_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>124493.00</td>\n",
       "      <td>1.244930e+05</td>\n",
       "      <td>124493.00</td>\n",
       "      <td>124493.00</td>\n",
       "      <td>124493.00</td>\n",
       "      <td>124493.00</td>\n",
       "      <td>124493.00</td>\n",
       "      <td>124493.00</td>\n",
       "      <td>124493.00</td>\n",
       "      <td>124493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.223875e+08</td>\n",
       "      <td>159.49</td>\n",
       "      <td>9.94</td>\n",
       "      <td>1.74</td>\n",
       "      <td>14.22</td>\n",
       "      <td>260173.03</td>\n",
       "      <td>0.29</td>\n",
       "      <td>12.45</td>\n",
       "      <td>2015-04-16 05:19:50.900692992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>6.128346e+07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>221452.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2015-02-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.227971e+08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>249800.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2015-03-27 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.833091e+08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>310266.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2015-06-17 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2.441405e+08</td>\n",
       "      <td>64968.00</td>\n",
       "      <td>24929.00</td>\n",
       "      <td>1666.00</td>\n",
       "      <td>98.00</td>\n",
       "      <td>689161.00</td>\n",
       "      <td>832.00</td>\n",
       "      <td>18701.00</td>\n",
       "      <td>2015-11-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.03</td>\n",
       "      <td>7.045934e+07</td>\n",
       "      <td>2179.67</td>\n",
       "      <td>185.75</td>\n",
       "      <td>22.91</td>\n",
       "      <td>15.94</td>\n",
       "      <td>99151.39</td>\n",
       "      <td>7.44</td>\n",
       "      <td>191.43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         failure    attribute1  attribute2  attribute3  attribute4  \\\n",
       "count  124493.00  1.244930e+05   124493.00   124493.00   124493.00   \n",
       "mean        0.00  1.223875e+08      159.49        9.94        1.74   \n",
       "min         0.00  0.000000e+00        0.00        0.00        0.00   \n",
       "25%         0.00  6.128346e+07        0.00        0.00        0.00   \n",
       "50%         0.00  1.227971e+08        0.00        0.00        0.00   \n",
       "75%         0.00  1.833091e+08        0.00        0.00        0.00   \n",
       "max         1.00  2.441405e+08    64968.00    24929.00     1666.00   \n",
       "std         0.03  7.045934e+07     2179.67      185.75       22.91   \n",
       "\n",
       "       attribute5  attribute6  attribute7  attribute9  \\\n",
       "count   124493.00   124493.00   124493.00   124493.00   \n",
       "mean        14.22   260173.03        0.29       12.45   \n",
       "min          1.00        8.00        0.00        0.00   \n",
       "25%          8.00   221452.00        0.00        0.00   \n",
       "50%         10.00   249800.00        0.00        0.00   \n",
       "75%         12.00   310266.00        0.00        0.00   \n",
       "max         98.00   689161.00      832.00    18701.00   \n",
       "std         15.94    99151.39        7.44      191.43   \n",
       "\n",
       "                             date_dt  \n",
       "count                         124493  \n",
       "mean   2015-04-16 05:19:50.900692992  \n",
       "min              2015-01-01 00:00:00  \n",
       "25%              2015-02-09 00:00:00  \n",
       "50%              2015-03-27 00:00:00  \n",
       "75%              2015-06-17 00:00:00  \n",
       "max              2015-11-02 00:00:00  \n",
       "std                              NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with failure: 106 out of 124,493 records \t 0.09%\n",
      "Number of devices with failure: 106 out of 1,169 devices \t 9.07%\n"
     ]
    }
   ],
   "source": [
    "# FAILURE distribution\n",
    "print(f'Number of records with failure: {len(df[df['failure']==1])} out of {len(df):,} records \\t {round((len(df[df['failure']==1])/len(df))*100,2)}%')\n",
    "print(f'Number of devices with failure: {len(df[df['failure']==1])} out of {df.device.nunique():,} devices \\t {round((len(df[df['failure']==1])/df.device.nunique())*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **APPROACHING THE PROBLEM**\n",
    "\n",
    "##### APPROACH #2\n",
    "As of right now we are preparing the dataset aggregating all data per device.\n",
    "- Our train data will be a random sample of devices (70% of all devices).\n",
    "- Our test data will be the remaining (30%) devices.\n",
    "- Here we would answer the question: Given today's data, what is the probability of the device failing TODAY.\n",
    "- **ASSUMPTION**: We receive the current date's attributes before it fail and we want to predict if the device would fail at the end of the day.\n",
    "    - I am not sure we can assume this...\n",
    "\n",
    "##### APPROACH #2\n",
    "We could also look at each datapoint, each event independently, and:\n",
    "- Train the data with part (70%) of the devices that have failed and the scenarios that lead to failure.\n",
    "- Test the data with the remaining (30%) of the devices that have failed and the probability of failure for each event.\n",
    "- Here the prediction will be: what is the probability of the device failing in the next event.\n",
    "    - This would answer our initial question: Should we apply maintenance to that device before it fails?\n",
    "- **ISSUE**: No aggregation would be done and the number of events with failure is way too small for this approach (106 failures/126,493 records = 0.09% event failure rate)\n",
    "\n",
    "##### APPROACH #3\n",
    "We could aggregate the data, but instead of observing the most recent event, we:\n",
    "- Aggregate the data up to the \"second to last\" event and have a new response variable: \"will fail in next event\"\n",
    "- Our train data will be a random sample of devices (70% of all devices).\n",
    "- Our test data will be the remaining (30%) devices.\n",
    "- Here we would answer the question: Given today's data, what is the probability of the device failing TOMORROW.\n",
    "\n",
    "**I believe that APPROACH #3 is the most adequate.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is not much information on what each attribute means, we will proceed to aggregate data per device and generate features from that point on.\n",
    "\n",
    "REMEMBER: We will aggregate the data up to the second to last most recent event for each device.\n",
    "\n",
    "For this we will need to: \n",
    "- remove the most recent record for each device,\n",
    "- Aggregate the data,\n",
    "- Add the second to last most recent event's features,\n",
    "- Add the response variable from the most recent record (which we assume we will not receive when making the predictions).\n",
    "    - The response variable will be named '`will_fail`'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "failure\n",
       "0    1068\n",
       "1     101\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df with all most recent record for each device.\n",
    "df_most_recent = (df[['device', 'date_dt']]\n",
    "                  .groupby('device')\n",
    "                  .agg(date_dt=('date_dt','max'))\n",
    "                  .reset_index()\n",
    "                  ).merge(df, how='left', on=['device', 'date_dt'])\n",
    "\n",
    "# df with all records except most recent for each device\n",
    "#df_except_most_recent = df[df[]]\n",
    "\n",
    "df_most_recent.failure.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have some interesting infromation: there are 5 devices from the 106 total devices with failure that did not have their failures as their respective very last event.\n",
    "\n",
    "Let's see which devices those are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1F0GPFZ', 'S1F136J0', 'W1F0KCP2', 'W1F0M35B', 'W1F11ZG9']\n",
      "number of rows these devices represent in df: 822 out of 124,493\n"
     ]
    }
   ],
   "source": [
    "df_temp = df.merge(df_most_recent[['device', 'date_dt']].rename(columns={'device':'_device', 'date_dt':'_date_dt'}), \n",
    "                   left_on=['device', 'date_dt'], \n",
    "                   right_on=['_device', '_date_dt'], \n",
    "                   how=\"outer\", \n",
    "                   indicator=True\n",
    "                   ).query('_merge==\"left_only\"').drop(columns=['_merge', '_device', '_date_dt'], axis=1)\n",
    "\n",
    "df_temp_clean = df_temp[df_temp['device'].isin(df_temp[df_temp['failure']==1].device.unique())].sort_values(['device', 'date_dt'])\n",
    "\n",
    "print(df_temp_clean.device.unique().tolist())\n",
    "print(f'number of rows these devices represent in df: {len(df[df['device'].isin(df_temp_clean.device.unique().tolist())])} out of {len(df):,}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could simply eliminate these devices from out dataset, but because we have a small amount of failed cases, \n",
    "we will simply remove the records that are not interesting to us, that is, the events after event with failure.\n",
    "\n",
    "For the records without failure (failure = 0) we will also remove the most recent record for which we are sure did not fail (otherwise we would be assuming that we know that the next event, which we don't have, would not fail).\n",
    "\n",
    "With all that being said, we will: \n",
    "- use the cumsum aggregation and remove all records for which cumsum > 0 (for devices with failure)\n",
    "- use \n",
    "- remove respective most recent record for devices without failure.\n",
    "- add the response variable 'will_fail' = 1 for devices with failure, and 0 for devices without failure.\n",
    "- we will then have two df's: one with `'will_fail'=1` and another with `'will_fail'=0`.\n",
    "- We then proceed to merge these two df's together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>device</th>\n",
       "      <th>failure</th>\n",
       "      <th>attribute1</th>\n",
       "      <th>attribute2</th>\n",
       "      <th>attribute3</th>\n",
       "      <th>attribute4</th>\n",
       "      <th>attribute5</th>\n",
       "      <th>attribute6</th>\n",
       "      <th>attribute7</th>\n",
       "      <th>attribute9</th>\n",
       "      <th>date_dt</th>\n",
       "      <th>will_fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F01085</td>\n",
       "      <td>0</td>\n",
       "      <td>215630672</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>407438</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>S1F01085</td>\n",
       "      <td>0</td>\n",
       "      <td>1650864</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>407438</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>S1F01085</td>\n",
       "      <td>0</td>\n",
       "      <td>124017368</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>407438</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>S1F01085</td>\n",
       "      <td>0</td>\n",
       "      <td>128073224</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>407439</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>S1F01085</td>\n",
       "      <td>0</td>\n",
       "      <td>97393448</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>408114</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    device  failure  attribute1  attribute2  attribute3  \\\n",
       "0  2015-01-01  S1F01085        0   215630672          56           0   \n",
       "1  2015-01-02  S1F01085        0     1650864          56           0   \n",
       "2  2015-01-03  S1F01085        0   124017368          56           0   \n",
       "3  2015-01-04  S1F01085        0   128073224          56           0   \n",
       "4  2015-01-05  S1F01085        0    97393448          56           0   \n",
       "\n",
       "   attribute4  attribute5  attribute6  attribute7  attribute9    date_dt  \\\n",
       "0          52           6      407438           0           7 2015-01-01   \n",
       "1          52           6      407438           0           7 2015-01-02   \n",
       "2          52           6      407438           0           7 2015-01-03   \n",
       "3          52           6      407439           0           7 2015-01-04   \n",
       "4          52           6      408114           0           7 2015-01-05   \n",
       "\n",
       "   will_fail  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the cumsum aggregation and remove all records for which cumsum > 0 (for devices with failure)\n",
    "\n",
    "## isolate cases with failure\n",
    "cases_with_failure = df[df['failure']==1].device.unique().tolist()\n",
    "df_devices_failure = df[df['device'].isin(cases_with_failure)].copy()\n",
    "## Create 'cumsum_failure'\n",
    "df_devices_failure['cumsum_failure'] = df_devices_failure.sort_values(['device','date']).groupby('device')['failure'].cumsum()\n",
    "## remove all records with 'cumsum_failure' > 0\n",
    "df_devices_failure = df_devices_failure[df_devices_failure['cumsum_failure']==0].drop(columns='cumsum_failure', axis=1)\n",
    "## add response variable: 'will_fail'\n",
    "df_devices_failure['will_fail'] = 1\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "# Remove respective most recent record for devices without failure.\n",
    "\n",
    "## isolate cases without failure\n",
    "cases_without_failure = df[~df['device'].isin(cases_with_failure)].device.unique().tolist()\n",
    "df_devices_nofailure = df[df['device'].isin(cases_without_failure)].copy()\n",
    "\n",
    "## create temporary df with device and most recent date, and remove these rows from df\n",
    "df_devices_nofailure = df_devices_nofailure.merge((df_devices_nofailure\n",
    "                                                   .groupby('device')\n",
    "                                                   .agg(most_recent_date=('date_dt','max'))\n",
    "                                                   .reset_index()\n",
    "                                                   .rename(columns={'device':'_device'})\n",
    "                                                   ),\n",
    "                                                  how='outer',\n",
    "                                                  left_on=['device', 'date_dt'], \n",
    "                                                  right_on=['_device', 'most_recent_date'], \n",
    "                                                  indicator=True).query('_merge==\"left_only\"').drop(columns=['_merge', '_device', 'most_recent_date'], axis=1)\n",
    "df_devices_nofailure['will_fail'] = 0\n",
    "\n",
    "df_devices_nofailure.head()\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "df_clean = pd.concat([df_devices_nofailure, df_devices_failure], )\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed to aggregate the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Aggregating the data**\n",
    "\n",
    "For each attribute we will create it's `mean`, `min`, `max`, `sum` and `nunique` version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['device', 'will_fail', 'attribute1_min', 'attribute1_max',\n",
      "       'attribute1_mean', 'attribute1_nunique', 'attribute2_min',\n",
      "       'attribute2_max', 'attribute2_mean', 'attribute2_nunique',\n",
      "       'attribute3_min', 'attribute3_max', 'attribute3_mean',\n",
      "       'attribute3_nunique', 'attribute4_min', 'attribute4_max',\n",
      "       'attribute4_mean', 'attribute4_nunique', 'attribute5_min',\n",
      "       'attribute5_max', 'attribute5_mean', 'attribute5_nunique',\n",
      "       'attribute6_min', 'attribute6_max', 'attribute6_mean',\n",
      "       'attribute6_nunique', 'attribute7_min', 'attribute7_max',\n",
      "       'attribute7_mean', 'attribute7_nunique', 'attribute9_min',\n",
      "       'attribute9_max', 'attribute9_mean', 'attribute9_nunique',\n",
      "       'date_dt_min', 'date_dt_max', 'date_dt_mean', 'date_dt_nunique'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# First aggregate the attributes and date var\n",
    "df_devices_att = (\n",
    "    df_clean[['device', 'attribute1', 'attribute2', 'attribute3', \n",
    "              'attribute4', 'attribute5', 'attribute6', 'attribute7', #'attribute8'\n",
    "              'attribute9', 'date_dt']]\n",
    "       .groupby('device')\n",
    "       .agg(['min','max', 'mean', 'nunique']) # , 'sum'])\n",
    "       ).reset_index()\n",
    "\n",
    "df_devices_att.columns = ['_'.join(col) for col in df_devices_att.columns.values]\n",
    "df_devices_att.rename(columns={'device_':'device'}, inplace=True)\n",
    "\n",
    "# Second, we generate the response variable for each device (makes no sense to aggregate 'will_fail' in min, max, mean, nunique)\n",
    "df_devices_resp = (\n",
    "    df_clean[['device', 'will_fail']]\n",
    "    .groupby('device')\n",
    "    .agg(will_fail=('will_fail','max'))\n",
    "    )\n",
    "\n",
    "df_devices = df_devices_resp.merge(df_devices_att, how='left', on='device')\n",
    "# df_devices.head()\n",
    "print(df_devices.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Most recent row's data\n",
    "\n",
    "Once we have a trained model, we will receive new data for prediction which will include:\n",
    "- Historical data on the previous days for a device,\n",
    "- Data on the curent date, for which we are trying to make the prediction.\n",
    "\n",
    "With that being said, the current (most recent) date's data is relevant for the prediction.\n",
    "\n",
    "Let's include this data in our agregated dataframe (df_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_devices = df_devices.merge(df, how='left', left_on=['device','date_dt_max'], right_on=['device','date_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['device', 'will_fail', 'attribute1_min', 'attribute1_max',\n",
       "       'attribute1_mean', 'attribute1_nunique', 'attribute2_min',\n",
       "       'attribute2_max', 'attribute2_mean', 'attribute2_nunique',\n",
       "       'attribute3_min', 'attribute3_max', 'attribute3_mean',\n",
       "       'attribute3_nunique', 'attribute4_min', 'attribute4_max',\n",
       "       'attribute4_mean', 'attribute4_nunique', 'attribute5_min',\n",
       "       'attribute5_max', 'attribute5_mean', 'attribute5_nunique',\n",
       "       'attribute6_min', 'attribute6_max', 'attribute6_mean',\n",
       "       'attribute6_nunique', 'attribute7_min', 'attribute7_max',\n",
       "       'attribute7_mean', 'attribute7_nunique', 'attribute9_min',\n",
       "       'attribute9_max', 'attribute9_mean', 'attribute9_nunique',\n",
       "       'date_dt_min', 'date_dt_max', 'date_dt_mean', 'date_dt_nunique', 'date',\n",
       "       'failure', 'attribute1', 'attribute2', 'attribute3', 'attribute4',\n",
       "       'attribute5', 'attribute6', 'attribute7', 'attribute9', 'date_dt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_devices.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the aggregated data to engineer features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### based on 'date_dt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by calculating the number of days we have data for each device (`date_dt_max-date_dt_min`).\n",
    "\n",
    "This feature will be called: `num_days`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_dt_max    datetime64[ns]\n",
      "date_dt_min    datetime64[ns]\n",
      "num_days                int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_dt_max</th>\n",
       "      <th>date_dt_min</th>\n",
       "      <th>num_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-10</td>\n",
       "      <td>2015-05-06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-16</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_dt_max date_dt_min  num_days\n",
       "0  2015-01-05  2015-01-01         4\n",
       "1  2015-05-10  2015-05-06         4\n",
       "2  2015-01-05  2015-01-01         4\n",
       "3  2015-02-16  2015-01-01        46\n",
       "4  2015-01-05  2015-01-01         4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_devices['num_days'] = (df_devices['date_dt_max']-df_devices['date_dt_min']).dt.days\n",
    "print(df_devices[['date_dt_max', 'date_dt_min', 'num_days']].dtypes)\n",
    "df_devices[['date_dt_max', 'date_dt_min', 'num_days']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most recent event we have happens in `date_dt_max`, so we will etract:\n",
    "- `date_dt_max_day`: what day did the last device's event happen on.\n",
    "- `date_dt_max_month`: what month did the last device's event happen on.\n",
    "- `date_dt_max_weekday`: what weekday did the last device's event happen on. (0 = monday, 6 = sunday).\n",
    "\n",
    "`date_dt_max_year`: we will ignore this feature for it is he same for all observations (2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date_dt_max_day  date_dt_max_month  date_dt_max_weekday\n",
      "count           1168.0             1168.0               1168.0\n",
      "mean              13.0                4.3                  2.7\n",
      "std                8.7                3.3                  2.4\n",
      "min                1.0                1.0                  0.0\n",
      "25%                5.0                1.0                  0.0\n",
      "50%               11.0                3.0                  2.0\n",
      "75%               21.0                8.0                  6.0\n",
      "max               31.0               10.0                  6.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_dt_max</th>\n",
       "      <th>date_dt_max_day</th>\n",
       "      <th>date_dt_max_month</th>\n",
       "      <th>date_dt_max_weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-16</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_dt_max  date_dt_max_day  date_dt_max_month  date_dt_max_weekday\n",
       "0  2015-01-05                5                  1                    0\n",
       "1  2015-05-10               10                  5                    6\n",
       "2  2015-01-05                5                  1                    0\n",
       "3  2015-02-16               16                  2                    0\n",
       "4  2015-01-05                5                  1                    0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date_dt_max_day\n",
    "df_devices['date_dt_max_day'] = df_devices['date_dt_max'].dt.day\n",
    "\n",
    "# date_dt_max_month\n",
    "df_devices['date_dt_max_month'] = df_devices['date_dt_max'].dt.month\n",
    "\n",
    "# date_dt_max_weekday\n",
    "df_devices['date_dt_max_weekday'] = df_devices['date_dt_max'].dt.weekday\n",
    "\n",
    "# VALIDATE\n",
    "print(df_devices[['date_dt_max_day', 'date_dt_max_month', 'date_dt_max_weekday']].describe().round(1))\n",
    "df_devices[['date_dt_max', 'date_dt_max_day', 'date_dt_max_month', 'date_dt_max_weekday']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device                         object\n",
       "will_fail                       int64\n",
       "attribute1_min                  int64\n",
       "attribute1_max                  int64\n",
       "attribute1_mean               float64\n",
       "attribute1_nunique              int64\n",
       "attribute2_min                  int64\n",
       "attribute2_max                  int64\n",
       "attribute2_mean               float64\n",
       "attribute2_nunique              int64\n",
       "attribute3_min                  int64\n",
       "attribute3_max                  int64\n",
       "attribute3_mean               float64\n",
       "attribute3_nunique              int64\n",
       "attribute4_min                  int64\n",
       "attribute4_max                  int64\n",
       "attribute4_mean               float64\n",
       "attribute4_nunique              int64\n",
       "attribute5_min                  int64\n",
       "attribute5_max                  int64\n",
       "attribute5_mean               float64\n",
       "attribute5_nunique              int64\n",
       "attribute6_min                  int64\n",
       "attribute6_max                  int64\n",
       "attribute6_mean               float64\n",
       "attribute6_nunique              int64\n",
       "attribute7_min                  int64\n",
       "attribute7_max                  int64\n",
       "attribute7_mean               float64\n",
       "attribute7_nunique              int64\n",
       "attribute9_min                  int64\n",
       "attribute9_max                  int64\n",
       "attribute9_mean               float64\n",
       "attribute9_nunique              int64\n",
       "date_dt_min            datetime64[ns]\n",
       "date_dt_max            datetime64[ns]\n",
       "date_dt_mean           datetime64[ns]\n",
       "date_dt_nunique                 int64\n",
       "date                           object\n",
       "failure                         int64\n",
       "attribute1                      int64\n",
       "attribute2                      int64\n",
       "attribute3                      int64\n",
       "attribute4                      int64\n",
       "attribute5                      int64\n",
       "attribute6                      int64\n",
       "attribute7                      int64\n",
       "attribute9                      int64\n",
       "date_dt                datetime64[ns]\n",
       "num_days                        int64\n",
       "date_dt_max_day                 int32\n",
       "date_dt_max_month               int32\n",
       "date_dt_max_weekday             int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_devices.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, from the date columns, we have the features:\n",
    "- `num_days`: (int64)\n",
    "- `date_dt_min`: (datetime64[ns])\n",
    "- `date_dt_max`: (datetime64[ns])\n",
    "- `date_dt_mean`: (datetime64[ns])\n",
    "- `date_dt_max_day`: (int32)\n",
    "- `date_dt_max_month`: (int32)\n",
    "- `date_dt_max_weekday`: (int32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### based on 'device'\n",
    "I noticed that there are some possible categories we could extract from the `device` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 3 charcaters: ['S1F', 'W1F', 'Z1F']\n",
      "first 4 charcaters: ['S1F0', 'S1F1', 'W1F0', 'W1F1', 'Z1F0', 'Z1F1', 'Z1F2']\n"
     ]
    }
   ],
   "source": [
    "# Extract the first three characters of the 'device' column\n",
    "df_devices['device_0_3'] = df_devices['device'].str[0:3]\n",
    "print(f'first 3 charcaters: {df_devices['device_0_3'].unique().tolist()}')\n",
    "\n",
    "# Extract the first three characters of the 'device' column (more granular)\n",
    "df_devices['device_0_4'] = df_devices['device'].str[0:4]\n",
    "print(f'first 4 charcaters: {df_devices['device_0_4'].unique().tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further on, we will apply encoding to these categorica variables. But before, out of curiosity, let's if there is any concentration of device failure in one of these categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_devices</th>\n",
       "      <th>will_fail_num</th>\n",
       "      <th>will_fail_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_0_3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1F</th>\n",
       "      <td>530</td>\n",
       "      <td>42</td>\n",
       "      <td>0.079245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1F</th>\n",
       "      <td>419</td>\n",
       "      <td>42</td>\n",
       "      <td>0.100239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z1F</th>\n",
       "      <td>219</td>\n",
       "      <td>22</td>\n",
       "      <td>0.100457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            num_devices  will_fail_num  will_fail_pct\n",
       "device_0_3                                           \n",
       "S1F                 530             42       0.079245\n",
       "W1F                 419             42       0.100239\n",
       "Z1F                 219             22       0.100457"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For first three characters ('device_0_3')\n",
    "df_devices[['device_0_3','will_fail']].groupby('device_0_3').agg(num_devices=('device_0_3','count'),\n",
    "                                                                 will_fail_num=('will_fail','sum'),\n",
    "                                                                 will_fail_pct=('will_fail','mean')\n",
    "                                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_devices</th>\n",
       "      <th>will_fail_num</th>\n",
       "      <th>will_fail_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_0_4</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Z1F1</th>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>0.134328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1F1</th>\n",
       "      <td>137</td>\n",
       "      <td>15</td>\n",
       "      <td>0.109489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1F0</th>\n",
       "      <td>282</td>\n",
       "      <td>27</td>\n",
       "      <td>0.095745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1F0</th>\n",
       "      <td>391</td>\n",
       "      <td>36</td>\n",
       "      <td>0.092072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z1F0</th>\n",
       "      <td>149</td>\n",
       "      <td>13</td>\n",
       "      <td>0.087248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1F1</th>\n",
       "      <td>139</td>\n",
       "      <td>6</td>\n",
       "      <td>0.043165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z1F2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            num_devices  will_fail_num  will_fail_pct\n",
       "device_0_4                                           \n",
       "Z1F1                 67              9       0.134328\n",
       "W1F1                137             15       0.109489\n",
       "W1F0                282             27       0.095745\n",
       "S1F0                391             36       0.092072\n",
       "Z1F0                149             13       0.087248\n",
       "S1F1                139              6       0.043165\n",
       "Z1F2                  3              0       0.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For first four characters ('device_0_4')\n",
    "df_devices[['device_0_4','will_fail']].groupby('device_0_4').agg(num_devices=('device_0_4','count'),\n",
    "                                                                 will_fail_num=('will_fail','sum'),\n",
    "                                                                 will_fail_pct=('will_fail','mean')\n",
    "                                                                 ).sort_values('will_fail_pct', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe we have created all possible relevant features with the data that we were given.\n",
    "\n",
    "Before we continue we will create a function that applies all of that preprocessing as well as the encoding of the categorical variabels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing and Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_train(df):\n",
    "    # -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n",
    "    # Drop duplicates\n",
    "    print('1) Dropping duplicates...')\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print('Done!')\n",
    "    print('-'*50)\n",
    "\n",
    "    # -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n",
    "    # Convert 'date' column from object to datetime\n",
    "    print('2) Converting \\'date\\' columns to datetime format...')\n",
    "    df['date_dt'] = pd.to_datetime(df['date'])\n",
    "    print('Done!')\n",
    "    print('-'*50)\n",
    "\n",
    "    # -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n",
    "    # Approach #3 data prep.\n",
    "    print(\"Approach #3 data prep. started... \")\n",
    "\n",
    "    # Use the cumsum aggregation and remove all records for which cumsum > 0 (for devices with failure)\n",
    "    ## isolate cases with failure\n",
    "    cases_with_failure = df[df['failure']==1].device.unique().tolist()\n",
    "    df_devices_failure = df[df['device'].isin(cases_with_failure)].copy()\n",
    "    ## Create 'cumsum_failure'\n",
    "    df_devices_failure['cumsum_failure'] = df_devices_failure.sort_values(['device','date']).groupby('device')['failure'].cumsum()\n",
    "    ## remove all records with 'cumsum_failure' > 0\n",
    "    df_devices_failure = df_devices_failure[df_devices_failure['cumsum_failure']==0].drop(columns='cumsum_failure', axis=1)\n",
    "    ## add response variable: 'will_fail'\n",
    "    df_devices_failure['will_fail'] = 1\n",
    "\n",
    "    # - - - - - - - - - - - - - - - -\n",
    "    # Remove respective most recent record for devices without failure.\n",
    "    ## isolate cases without failure\n",
    "    cases_without_failure = df[~df['device'].isin(cases_with_failure)].device.unique().tolist()\n",
    "    df_devices_nofailure = df[df['device'].isin(cases_without_failure)].copy()\n",
    "\n",
    "    ## create temporary df with device and most recent date, and remove these rows from df\n",
    "    df_devices_nofailure = df_devices_nofailure.merge((df_devices_nofailure\n",
    "                                                    .groupby('device')\n",
    "                                                    .agg(most_recent_date=('date_dt','max'))\n",
    "                                                    .reset_index()\n",
    "                                                    .rename(columns={'device':'_device'})\n",
    "                                                    ),\n",
    "                                                    how='outer',\n",
    "                                                    left_on=['device', 'date_dt'], \n",
    "                                                    right_on=['_device', 'most_recent_date'], \n",
    "                                                    indicator=True).query('_merge==\"left_only\"').drop(columns=['_merge', '_device', 'most_recent_date'], axis=1)\n",
    "    df_devices_nofailure['will_fail'] = 0\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - -\n",
    "    df_clean = pd.concat([df_devices_nofailure, df_devices_failure])\n",
    "\n",
    "    print('Done!')\n",
    "    print('-'*50)\n",
    "\n",
    "    # -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n",
    "    # Aggregating the data\n",
    "    print('3) Aggergating the data (groupby \\'device\\')...')\n",
    "\n",
    "    # First aggregate the attributes and date var\n",
    "    df_devices_att = (\n",
    "        df_clean[['device', 'attribute1', 'attribute2', 'attribute3', \n",
    "                'attribute4', 'attribute5', 'attribute6', 'attribute7', #'attribute8'\n",
    "                'attribute9', 'date_dt']]\n",
    "        .groupby('device')\n",
    "        .agg(['min','max', 'mean', 'nunique']) # , 'sum'])\n",
    "        ).reset_index()\n",
    "\n",
    "    df_devices_att.columns = ['_'.join(col) for col in df_devices_att.columns.values]\n",
    "    df_devices_att.rename(columns={'device_':'device'}, inplace=True)\n",
    "\n",
    "    # Second, we generate the response variable for each device (makes no sense to aggregate 'will_fail' in min, max, mean, nunique)\n",
    "    df_devices_resp = (\n",
    "        df_clean[['device', 'will_fail']]\n",
    "        .groupby('device')\n",
    "        .agg(will_fail=('will_fail','max'))\n",
    "        )\n",
    "\n",
    "    df_devices = df_devices_resp.merge(df_devices_att, how='left', on='device')\n",
    "    # df_devices.head()\n",
    "    print(df_devices.columns)\n",
    "    \n",
    "    print('Done!')\n",
    "    print('-'*50)\n",
    "\n",
    "    # -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n",
    "    # Feature Engineering\n",
    "    print('4) Feature Engineering phase:')\n",
    "    \n",
    "    # 'num_days'\n",
    "    print(\"creating 'num_days'...\")\n",
    "    df_devices['num_days'] = (df_devices['date_dt_max']-df_devices['date_dt_min']).dt.days\n",
    "    print(\"'num_days' created!\")\n",
    "\n",
    "    # 'date_dt_max_day'\n",
    "    print(\"creating 'date_dt_max_day'...\")\n",
    "    df_devices['date_dt_max_day'] = df_devices['date_dt_max'].dt.day\n",
    "    print(\"'date_dt_max_day' created!\")\n",
    "\n",
    "    # 'date_dt_max_month'\n",
    "    print(\"creating 'date_dt_max_month'...\")\n",
    "    df_devices['date_dt_max_month'] = df_devices['date_dt_max'].dt.month\n",
    "    print(\"'date_dt_max_month' created!\")\n",
    "\n",
    "    # 'date_dt_max_weekday'\n",
    "    print(\"creating 'date_dt_max_weekday'...\")\n",
    "    df_devices['date_dt_max_weekday'] = df_devices['date_dt_max'].dt.weekday\n",
    "    print(\"'date_dt_max_weekday' created!\")\n",
    "    \n",
    "    # 'device_0_4'\n",
    "    print(\"creating 'device_0_4'...\")\n",
    "    df_devices['device_0_4'] = df_devices['device'].str[0:4]\n",
    "    print(\"'device_0_4' created!\")\n",
    "\n",
    "    print('Feature Engineering phase done!')\n",
    "    print('-'*50)\n",
    "\n",
    "    # -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n",
    "    print('PREPROCESSING IS DONE!')\n",
    "    return df_devices[[\n",
    "        'device', \n",
    "        # 'date', 'failure', 'date_dt',\n",
    "        'date_dt_min', 'date_dt_max', 'num_days', 'date_dt_mean',\n",
    "        'date_dt_max_day', 'date_dt_max_month', 'date_dt_max_weekday',\n",
    "        'device_0_4',\n",
    "        'attribute1', 'attribute1_min', 'attribute1_max', 'attribute1_mean', 'attribute1_nuniq', \n",
    "        'attribute2', 'attribute2_min', 'attribute2_max', 'attribute2_mean', 'attribute2_nuniq', \n",
    "        'attribute3', 'attribute3_min', 'attribute3_max', 'attribute3_mean', 'attribute3_nuniq', \n",
    "        'attribute4', 'attribute4_min', 'attribute4_max', 'attribute4_mean', 'attribute4_nuniq', \n",
    "        'attribute5', 'attribute5_min', 'attribute5_max', 'attribute5_mean', 'attribute5_nuniq', \n",
    "        'attribute6', 'attribute6_min', 'attribute6_max', 'attribute6_mean', 'attribute6_nuniq', \n",
    "        'attribute7', 'attribute7_min', 'attribute7_max', 'attribute7_mean', 'attribute7_nuniq', \n",
    "        'attribute8', 'attribute8_min', 'attribute8_max', 'attribute8_mean', 'attribute8_nuniq', \n",
    "        'attribute9', 'attribute9_min', 'attribute9_max', 'attribute9_mean', 'attribute9_nuniq',\n",
    "        'will_fail']]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE \n",
    "\n",
    "### PENDING FORM HERE\n",
    "- Create the preprocessing_test function (not involving the will_fail response variable of course)\n",
    "- Create sample function.\n",
    "- Correlation matrix and scatter matrix.\n",
    "- Test out a couple of algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['device', 'will_fail', 'attribute1_min', 'attribute1_max',\n",
       "       'attribute1_mean', 'attribute1_nunique', 'attribute2_min',\n",
       "       'attribute2_max', 'attribute2_mean', 'attribute2_nunique',\n",
       "       'attribute3_min', 'attribute3_max', 'attribute3_mean',\n",
       "       'attribute3_nunique', 'attribute4_min', 'attribute4_max',\n",
       "       'attribute4_mean', 'attribute4_nunique', 'attribute5_min',\n",
       "       'attribute5_max', 'attribute5_mean', 'attribute5_nunique',\n",
       "       'attribute6_min', 'attribute6_max', 'attribute6_mean',\n",
       "       'attribute6_nunique', 'attribute7_min', 'attribute7_max',\n",
       "       'attribute7_mean', 'attribute7_nunique', 'attribute9_min',\n",
       "       'attribute9_max', 'attribute9_mean', 'attribute9_nunique',\n",
       "       'date_dt_min', 'date_dt_max', 'date_dt_mean', 'date_dt_nunique', 'date',\n",
       "       'failure', 'attribute1', 'attribute2', 'attribute3', 'attribute4',\n",
       "       'attribute5', 'attribute6', 'attribute7', 'attribute9', 'date_dt',\n",
       "       'num_days', 'date_dt_max_day', 'date_dt_max_month',\n",
       "       'date_dt_max_weekday', 'device_0_3', 'device_0_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupby('device').agg(failure_sum=('failure','sum')).reset_index()).groupby('failure_sum').agg(num_devices=('device','nunique'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage failed devices\n",
    "print(f'{round((df_devices[df_devices['failed']==1].failed.sum()/len(df_devices))*100,2)}%')\n",
    "\n",
    "df_devices.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(df):\n",
    "    try:\n",
    "        correlation_matrix = df.corr()\n",
    "        return correlation_matrix\n",
    "    except KeyError:\n",
    "        print(f\"DataFrame not found.\")\n",
    "        return None\n",
    "    \n",
    "correlation_matrix(df_devices.drop(['device', 'date_min', 'date_max'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_ratio(categorical_feature, numeric_feature):\n",
    "    cats, freqs = np.unique(categorical_feature, return_counts=True)\n",
    "    numeric_mean = np.mean(numeric_feature)\n",
    "    sig_y_bar = 0\n",
    "    for i in range(len(cats)):\n",
    "        category_mean = np.mean(numeric_feature[categorical_feature == cats[i]])\n",
    "        sig_y_bar += np.square(category_mean - numeric_mean) * freqs[i]\n",
    "    sig_y = np.sum(np.square(numeric_feature - numeric_mean))\n",
    "    statistic = np.sqrt(sig_y_bar / sig_y)\n",
    "    return statistic\n",
    "\n",
    "data = df_devices.drop(['device', 'date_min', 'date_max'], axis=1)\n",
    "\n",
    "for each in ['pearson', 'spearman', 'kendall', correlation_ratio]:\n",
    "    corr = data.corr(method=each)\n",
    "    ax = sns.heatmap(\n",
    "        corr, \n",
    "        vmin=-1, vmax=1, center=0,\n",
    "        cmap=sns.diverging_palette(20, 220, n=200),\n",
    "        square=True\n",
    "    )\n",
    "    ax.set_xticklabels(\n",
    "        ax.get_xticklabels(),\n",
    "        rotation=45,\n",
    "        horizontalalignment='right'\n",
    "    )\n",
    "    try:\n",
    "        ax.set_title(each.upper())\n",
    "    except:\n",
    "        ax.set_title(each.__name__.upper())\n",
    "                 \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.plotting.scatter_matrix(data)\n",
    "# STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - STOPPED HERE - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPECIFIC CASES (visual checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('failure').agg(num_unique_devices=('device','nunique'),\n",
    "                          num_incidents=('device','count')\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.device.value_counts()\n",
    "\n",
    "#df[df['failure']==1][['device', 'failure']].drop_duplicates()\n",
    "devices_with_failure = df[df['failure']==1].device.unique().tolist()\n",
    "print(devices_with_failure)\n",
    "\n",
    "\n",
    "devices_without_failure = df[~df['device'].isin(devices_with_failure)].device.unique().tolist()\n",
    "print(devices_without_failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['device'].isin(devices_with_failure)].sort_values(['device','date']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'W1F0T034'\n",
    "\n",
    "#device = 'W1F1230J'\n",
    "\n",
    "print(len(df[df['device']==device].sort_values(['device','date'])))\n",
    "df[df['device']==device].sort_values(['device','date']).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='S1F0RRB1'\n",
    "\n",
    "print(len(df[df['device']==device].sort_values(['device','date'])))\n",
    "df[df['device']==device].sort_values(['device','date']).tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy()\n",
    "df_test['7_8'] = df_test['attribute7'] == df_test['attribute8']\n",
    "df_test['7_8'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meli_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
